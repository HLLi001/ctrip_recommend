# main.py
import logging
import os
import sys
import time

# ä¿®å¤å¯¼å…¥è·¯å¾„ - æ·»åŠ utilsç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
utils_dir = os.path.join(current_dir, 'utils')
sys.path.append(utils_dir)

# çŽ°åœ¨å¯ä»¥å¯¼å…¥configäº†
from config import config
from spiders.ctrip_spider import CtripSpider
from file_storage import FileStorage

def setup_logging():
    """é…ç½®æ—¥å¿—"""
    os.makedirs(config.LOG_DIR, exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, config.LOG_LEVEL),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(os.path.join(config.LOG_DIR, 'ctrip_spider.log'), encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def validate_data_quality(sights_data):
    """éªŒè¯æ•°æ®è´¨é‡"""
    logger = logging.getLogger('main')
    
    if not sights_data:
        logger.warning("æ²¡æœ‰æ•°æ®å¯éªŒè¯")
        return
    
    total = len(sights_data)
    
    # ç»Ÿè®¡å„é¡¹æ•°æ®çš„å®Œæ•´æ€§
    name_complete = sum(1 for s in sights_data if s.get('name') and s.get('name') != 'æœªçŸ¥')
    rating_complete = sum(1 for s in sights_data if s.get('rating', 0) > 0)
    address_complete = sum(1 for s in sights_data if s.get('address') and s.get('address') != 'æœªçŸ¥')
    intro_complete = sum(1 for s in sights_data if s.get('introduction'))
    
    logger.info("ðŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š:")
    logger.info(f"   æ€»æ•°æ®é‡: {total}")
    logger.info(f"   åç§°å®Œæ•´çŽ‡: {name_complete}/{total} ({name_complete/total*100:.1f}%)")
    logger.info(f"   è¯„åˆ†å®Œæ•´çŽ‡: {rating_complete}/{total} ({rating_complete/total*100:.1f}%)")
    logger.info(f"   åœ°å€å®Œæ•´çŽ‡: {address_complete}/{total} ({address_complete/total*100:.1f}%)")
    logger.info(f"   ä»‹ç»å®Œæ•´çŽ‡: {intro_complete}/{total} ({intro_complete/total*100:.1f}%)")

def main():
    """ä¸»ç¨‹åº - å¢žå¼ºç‰ˆ"""
    setup_logging()
    logger = logging.getLogger('main')
    
    logger.info("=" * 50)
    logger.info("å¼€å§‹æºç¨‹æ—…è¡Œæ•°æ®çˆ¬å–ï¼ˆå¢žå¼ºç‰ˆï¼‰...")
    logger.info("=" * 50)
    
    try:
        # åˆå§‹åŒ–å­˜å‚¨
        storage = FileStorage()
        
        # å¼€å§‹çˆ¬è™«
        spider = CtripSpider()
        
        # å¯é€‰ï¼šå…ˆè¿›è¡Œå°è§„æ¨¡æµ‹è¯•
        if config.DEBUG_MODE:
            logger.info("è°ƒè¯•æ¨¡å¼ï¼šå…ˆæµ‹è¯•å°‘é‡æ•°æ®")
            test_sights = spider.crawl_all_sights(max_sights=10)
            if test_sights:
                logger.info("æµ‹è¯•æˆåŠŸï¼Œå¼€å§‹å®Œæ•´çˆ¬å–")
            else:
                logger.error("æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥çˆ¬è™«é…ç½®")
                return
        
        logger.info(f"è®¡åˆ’çˆ¬å–æœ€å¤š {config.MAX_SIGHTS} ä¸ªæ™¯ç‚¹")
        
        # çˆ¬å–æ™¯ç‚¹æ•°æ®
        sights_data = spider.crawl_all_sights(max_sights=config.MAX_SIGHTS)
        
        if sights_data:
            # æ•°æ®æ¸…æ´—
            cleaned_data = storage.clean_sight_data(sights_data)
            logger.info(f"æ•°æ®æ¸…æ´—åŽå‰©ä½™ {len(cleaned_data)} ä¸ªæœ‰æ•ˆæ™¯ç‚¹")
            
            # æ•°æ®è´¨é‡éªŒè¯
            validate_data_quality(cleaned_data)
            
            # ä¿å­˜æ•°æ®
            json_file = storage.save_sights_to_json(cleaned_data)
            csv_file = storage.save_sights_to_csv(cleaned_data)
            
            logger.info("=" * 50)
            logger.info(f"çˆ¬è™«å®Œæˆï¼æˆåŠŸçˆ¬å– {len(cleaned_data)} ä¸ªæ™¯ç‚¹æ•°æ®")
            if json_file:
                logger.info(f"JSONæ–‡ä»¶: {json_file}")
            if csv_file:
                logger.info(f"CSVæ–‡ä»¶: {csv_file}")
            logger.info("=" * 50)
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
            show_data_stats(cleaned_data)
            
            # å¯é€‰ï¼šçˆ¬å–è¯„è®ºæ•°æ®
            if config.CRAWL_REVIEWS:
                logger.info("å¼€å§‹çˆ¬å–è¯„è®ºæ•°æ®...")
                all_reviews = []
                for sight in cleaned_data[:config.MAX_REVIEWS_PER_SIGHT]:  # é™åˆ¶æ•°é‡ï¼Œé¿å…è¯·æ±‚è¿‡å¤š
                    reviews = spider.get_sight_reviews(sight['url'], max_reviews=10)
                    for review in reviews:
                        review['sight_name'] = sight['name']
                    all_reviews.extend(reviews)
                    time.sleep(2)  # è¯„è®ºè¯·æ±‚é—´éš”
                
                if all_reviews:
                    review_json_file = storage.save_reviews_to_json(all_reviews)
                    review_csv_file = storage.save_reviews_to_csv(all_reviews)
                    logger.info(f"æˆåŠŸçˆ¬å– {len(all_reviews)} æ¡è¯„è®º")
                    if review_json_file:
                        logger.info(f"è¯„è®ºJSONæ–‡ä»¶: {review_json_file}")
                    if review_csv_file:
                        logger.info(f"è¯„è®ºCSVæ–‡ä»¶: {review_csv_file}")
            
        else:
            logger.warning("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥çˆ¬è™«é…ç½®æˆ–ç½‘ç«™ç»“æž„")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())

def show_data_stats(sights_data):
    """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯ - ç§»é™¤åŸŽå¸‚ä¿¡æ¯"""
    if not sights_data:
        return
    
    logger = logging.getLogger('main')
    
    # åŸºæœ¬ç»Ÿè®¡
    total_sights = len(sights_data)
    
    # è¯„åˆ†ç»Ÿè®¡
    ratings = [sight.get('rating', 0) for sight in sights_data if sight.get('rating', 0) > 0]
    if ratings:
        avg_rating = sum(ratings) / len(ratings)
        max_rating = max(ratings)
        min_rating = min(ratings)
    else:
        avg_rating = max_rating = min_rating = 0
    
    # è¯„è®ºæ•°ç»Ÿè®¡
    review_counts = [sight.get('review_count', 0) for sight in sights_data]
    total_reviews = sum(review_counts)
    avg_reviews = total_reviews / total_sights if total_sights > 0 else 0
    
    # æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡
    name_complete = sum(1 for s in sights_data if s.get('name') and s.get('name') != 'æœªçŸ¥')
    rating_complete = sum(1 for s in sights_data if s.get('rating', 0) > 0)
    address_complete = sum(1 for s in sights_data if s.get('address') and s.get('address') != 'æœªçŸ¥')
    intro_complete = sum(1 for s in sights_data if s.get('introduction'))
    
    logger.info("ðŸ“Š è¯¦ç»†æ•°æ®ç»Ÿè®¡:")
    logger.info(f"   æ€»æ™¯ç‚¹æ•°: {total_sights}")
    logger.info(f"   å¹³å‡è¯„åˆ†: {avg_rating:.2f} (æœ€é«˜: {max_rating:.1f}, æœ€ä½Ž: {min_rating:.1f})")
    logger.info(f"   æ€»è¯„è®ºæ•°: {total_reviews} (å¹³å‡: {avg_reviews:.1f})")
    
    logger.info("âœ… æ•°æ®å®Œæ•´æ€§:")
    logger.info(f"   åç§°å®Œæ•´çŽ‡: {name_complete}/{total_sights} ({name_complete/total_sights*100:.1f}%)")
    logger.info(f"   è¯„åˆ†å®Œæ•´çŽ‡: {rating_complete}/{total_sights} ({rating_complete/total_sights*100:.1f}%)")
    logger.info(f"   åœ°å€å®Œæ•´çŽ‡: {address_complete}/{total_sights} ({address_complete/total_sights*100:.1f}%)")
    logger.info(f"   ä»‹ç»å®Œæ•´çŽ‡: {intro_complete}/{total_sights} ({intro_complete/total_sights*100:.1f}%)")
    
    # è¯„åˆ†åˆ†å¸ƒ
    rating_ranges = {'5æ˜Ÿ': 0, '4æ˜Ÿ': 0, '3æ˜Ÿ': 0, '2æ˜Ÿ': 0, '1æ˜Ÿ': 0}
    for rating in ratings:
        if rating >= 4.5:
            rating_ranges['5æ˜Ÿ'] += 1
        elif rating >= 3.5:
            rating_ranges['4æ˜Ÿ'] += 1
        elif rating >= 2.5:
            rating_ranges['3æ˜Ÿ'] += 1
        elif rating >= 1.5:
            rating_ranges['2æ˜Ÿ'] += 1
        else:
            rating_ranges['1æ˜Ÿ'] += 1
    
    logger.info("â­ è¯„åˆ†åˆ†å¸ƒ:")
    for range_name, count in rating_ranges.items():
        if count > 0:
            percentage = (count / len(ratings)) * 100
            logger.info(f"   {range_name}: {count}ä¸ªæ™¯ç‚¹ ({percentage:.1f}%)")

if __name__ == "__main__":
    main()